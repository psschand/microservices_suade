{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nInstall Docker\\nInstall Docker for Mac: https://docs.docker.com/docker-for-mac/install/\\nOPTION 1: Run Postgres using a single Docker command\\nRun a postgres container\\nuses the official docker postgres 11 image\\nuses a named volume, my_dbdata, to store postgres data\\nexposes port 54320 to the host\\nsets the container name to my_postgres\\nuses the -d flag to run in the background\\n$ docker run -d --name my_postgres -v my_dbdata:/var/lib/postgresql/data -p 54320:5432 postgres:11\\nOPTION 2: Run Postgres using Docker Compose\\nCreate a docker-compose.yml file\\n$ mkdir /tmp/myproject\\n$ cd /tmp/myproject\\nCreate a new file docker-compose.yml:\\n\\nversion: \"3\"\\nservices:\\n  db:\\n    image: \"postgres:11\"\\n    container_name: \"my_postgres\"\\n    ports:\\n      - \"54320:5432\"\\n    volumes:\\n      - my_dbdata:/var/lib/postgresql/data\\nvolumes:\\n  my_dbdata:\\n\\n  \\nuses docker compose file version 3\\nsets up a service named \"db\" (this name can be used with docker-compose commands)\\nuses the postgres:11 image from hub.docker.com\\ncreates a container named \"my_postgres\"\\nconnects port 5432 inside Docker as port 54320 on the host machine\\nuses a named volume, \"my_dbdata\", for storing the database data. Even if the container and image are deleted, the volume will remain unless explicitly deleted using docker volume rm.\\nfor more information, see the Docker Compose file reference\\nStart Postgres\\nPull the postgres image from hub.docker.com, create a container named \"my_postgres\", and start it in the background:\\n\\n$ docker-compose up -d\\n\\n'"
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "'''\n",
    "Install Docker\n",
    "Install Docker for Mac: https://docs.docker.com/docker-for-mac/install/\n",
    "OPTION 1: Run Postgres using a single Docker command\n",
    "Run a postgres container\n",
    "uses the official docker postgres 11 image\n",
    "uses a named volume, my_dbdata, to store postgres data\n",
    "exposes port 54320 to the host\n",
    "sets the container name to my_postgres\n",
    "uses the -d flag to run in the background\n",
    "$ docker run -d --name my_postgres -v my_dbdata:/var/lib/postgresql/data -p 54320:5432 postgres:11\n",
    "OPTION 2: Run Postgres using Docker Compose\n",
    "Create a docker-compose.yml file\n",
    "$ mkdir /tmp/myproject\n",
    "$ cd /tmp/myproject\n",
    "Create a new file docker-compose.yml:\n",
    "\n",
    "version: \"3\"\n",
    "services:\n",
    "  db:\n",
    "    image: \"postgres:11\"\n",
    "    container_name: \"my_postgres\"\n",
    "    ports:\n",
    "      - \"54320:5432\"\n",
    "    volumes:\n",
    "      - my_dbdata:/var/lib/postgresql/data\n",
    "volumes:\n",
    "  my_dbdata:\n",
    "\n",
    "  \n",
    "uses docker compose file version 3\n",
    "sets up a service named \"db\" (this name can be used with docker-compose commands)\n",
    "uses the postgres:11 image from hub.docker.com\n",
    "creates a container named \"my_postgres\"\n",
    "connects port 5432 inside Docker as port 54320 on the host machine\n",
    "uses a named volume, \"my_dbdata\", for storing the database data. Even if the container and image are deleted, the volume will remain unless explicitly deleted using docker volume rm.\n",
    "for more information, see the Docker Compose file reference\n",
    "Start Postgres\n",
    "Pull the postgres image from hub.docker.com, create a container named \"my_postgres\", and start it in the background:\n",
    "\n",
    "$ docker-compose up -d\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'See that it\\'s working\\nSee the logs:\\n\\n$ docker logs -f my_postgres\\nTry running psql:\\n\\n$ docker exec -it my_postgres psql -U postgres\\nhit CTRL+D to exit\\n\\nFor other commands such as starting, stopping, listing or deleting, see my Docker cheat sheet.\\n\\nCreate a database\\n$ docker exec -it my_postgres psql -U postgres -c \"create database my_database\"\\nConnect using Python and psycopg2\\n$ python3.6 -m venv myenv\\n$ source myenv/bin/activate\\n$ pip install psycopg2-binary'"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "'''See that it's working\n",
    "See the logs:\n",
    "\n",
    "$ docker logs -f my_postgres\n",
    "Try running psql:\n",
    "\n",
    "$ docker exec -it my_postgres psql -U postgres\n",
    "hit CTRL+D to exit\n",
    "\n",
    "For other commands such as starting, stopping, listing or deleting, see my Docker cheat sheet.\n",
    "\n",
    "Create a database\n",
    "$ docker exec -it my_postgres psql -U postgres -c \"create database my_database\"\n",
    "Connect using Python and psycopg2\n",
    "$ python3.6 -m venv myenv\n",
    "$ source myenv/bin/activate\n",
    "$ pip install psycopg2-binary'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'psycopg2.extensions.connection' object has no attribute 'execute'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-98db7a1a509f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morderlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscounted_amount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'psycopg2.extensions.connection' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host='192.168.99.100',\n",
    "    port=5436,\n",
    "    dbname='reports',\n",
    "    user='postgres',\n",
    "    password='postgres',\n",
    "    \n",
    ")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE TABLE IF NOT EXISTS test (id serial PRIMARY KEY, num integer, data varchar);\")\n",
    "\n",
    "from sqlalchemy.sql import select\n",
    "import sqlalchemy as db\n",
    "s=select([db.func.avg(orderlines.columns.discounted_amount),orders.columns.created_at]).group_by(orders.columns.created_at)\n",
    "result = conn.execute(s)\n",
    "print(result)\n",
    "for row in result:\n",
    "   print (row)\n",
    "cur.execute(\"SELECT * FROM test;\")\n",
    "result = cur.fetchone()\n",
    "print(result)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, ForeignKey\n",
    "# engine = create_engine('sqlite:///college.db', echo=True)\n",
    "\n",
    "db_string = \"postgresql://postgres:postgres@192.168.99.100:5436/reports\"\n",
    "engine = create_engine(db_string)\n",
    "meta = MetaData()\n",
    "\n",
    "conn = engine.connect()\n",
    "students = Table(\n",
    "   'students', meta, \n",
    "   Column('id', Integer, primary_key = True), \n",
    "   Column('name', String), \n",
    "   Column('lastname', String), \n",
    ")\n",
    "meta.create_all(engine)\n",
    "conn.execute(students.insert(), [\n",
    "   {'name':'Ravi', 'lastname':'Kapoor'},\n",
    "   {'name':'Rajiv', 'lastname' : 'Khanna'},\n",
    "   {'name':'Komal','lastname' : 'Bhandari'},\n",
    "   {'name':'Abdul','lastname' : 'Sattar'},\n",
    "   {'name':'Priya','lastname' : 'Rajhans'},\n",
    "])\n",
    "\n",
    "addresses = Table(\n",
    "   'addresses', meta, \n",
    "   Column('id', Integer, primary_key = True), \n",
    "   Column('st_id', Integer), \n",
    "   Column('postal_add', String), \n",
    "   Column('email_add', String)\n",
    ")\n",
    "meta.create_all(engine)\n",
    "conn.execute(addresses.insert(), [\n",
    "   {'st_id':1, 'postal_add':'Shivajinagar Pune', 'email_add':'ravi@gmail.com'},\n",
    "   {'st_id':1, 'postal_add':'ChurchGate Mumbai', 'email_add':'kapoor@gmail.com'},\n",
    "   {'st_id':3, 'postal_add':'Jubilee Hills Hyderabad', 'email_add':'komal@gmail.com'},\n",
    "   {'st_id':5, 'postal_add':'MG Road Bangaluru', 'email_add':'as@yahoo.com'},\n",
    "   {'st_id':2, 'postal_add':'Cannought Place new Delhi', 'email_add':'admin@khanna.com'},\n",
    "])\n",
    "\n",
    "meta.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Exception during reset or similar\nTraceback (most recent call last):\n  File \"C:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 693, in _finalize_fairy\n    fairy._reset(pool)\n  File \"C:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 880, in _reset\n    pool._dialect.do_rollback(self)\n  File \"C:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 540, in do_rollback\n    dbapi_connection.rollback()\npsycopg2.OperationalError: could not receive data from server: Software caused connection abort (0x00002745/10053)\n\n(1, 'Ravi', 'Kapoor', 1, 1, 'Shivajinagar Pune', 'ravi@gmail.com')\n(1, 'Ravi', 'Kapoor', 2, 1, 'ChurchGate Mumbai', 'kapoor@gmail.com')\n(3, 'Komal', 'Bhandari', 3, 3, 'Jubilee Hills Hyderabad', 'komal@gmail.com')\n(5, 'Priya', 'Rajhans', 4, 5, 'MG Road Bangaluru', 'as@yahoo.com')\n(2, 'Rajiv', 'Khanna', 5, 2, 'Cannought Place new Delhi', 'admin@khanna.com')\n"
    }
   ],
   "source": [
    "from sqlalchemy.sql import select\n",
    "s = select([students, addresses]).where(students.c.id == addresses.c.st_id)\n",
    "result = conn.execute(s)\n",
    "\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, ForeignKey\n",
    "# engine = create_engine('sqlite:///college.db', echo=True)\n",
    "from sqlalchemy import Column, Integer, String, DateTime\n",
    "from datetime import datetime\n",
    "db_string = \"postgresql://postgres:postgres@192.168.99.100:5436/reports\"\n",
    "engine = create_engine(db_string)\n",
    "meta = MetaData()\n",
    "\n",
    "conn = engine.connect()\n",
    "\n",
    "# ins = orders.drop()\n",
    "# conn = engine.connect()\n",
    "# result = conn.execute(ins)\n",
    "\n",
    "# orders.drop(engine) #drops a single table\n",
    "meta.drop_all(engine) #drops all the tables in the database\n",
    "\n",
    "orders = Table(\n",
    "   'orders', meta, \n",
    "   Column('id', Integer, primary_key = True), \n",
    "   Column('vendor_id', String), \n",
    "   Column('customer_id', String), \n",
    "   Column('created_at', DateTime,default=datetime.utcnow), \n",
    ")\n",
    "meta.create_all(engine)\n",
    "\n",
    "conn.execute(orders.insert(), [\n",
    "   {'vendor_id':'Ravi', 'customer_id':'Kapoor','created_at':datetime(2019, 4, 13)},\n",
    "   {'vendor_id':'Rajiv', 'customer_id' : 'Khanna','created_at':datetime(2016, 9, 1)},\n",
    "   {'vendor_id':'Komal','customer_id' : 'Bhandari','created_at':datetime(2017, 2, 3)},\n",
    "   {'vendor_id':'Abdul','customer_id' : 'Sattar','created_at':datetime(2018, 3, 5)},\n",
    "   {'vendor_id':'Priya','customer_id' : 'Rajhans','created_at':datetime(2018, 7, 5)},\n",
    "   {'vendor_id':'Priya','customer_id' : 'Rajhans','created_at':datetime(2020, 5, 4)},\n",
    "\n",
    "])\n",
    "orderlines = Table(\n",
    "   'orderlines', meta, \n",
    "   Column('id', Integer, primary_key = True), \n",
    "   Column('product_id', Integer), \n",
    "   Column('product_description', String), \n",
    "   Column('product_price', Integer),\n",
    "   Column('discount_rate', Integer), \n",
    "   Column('quantity', Integer),\n",
    "   Column('full_price_amount', Integer), \n",
    "   Column('discounted_amount', Integer),\n",
    "   Column('vat_amount', Integer), \n",
    "   Column('total_amount', Integer),\n",
    "   \n",
    ")\n",
    "meta.create_all(engine)\n",
    "conn.execute(orderlines.insert(), [\n",
    "   {'product_id':1, 'product_description':'Some product', 'product_price':5058,'discount_rate':1,'quantity':2,'full_price_amount':5058,'discounted_amount':58,'vat_amount':400,'total_amount':5000},\n",
    "      {'product_id':2, 'product_description':'Some product', 'product_price':5058,'discount_rate':1,'quantity':2,'full_price_amount':5058,'discounted_amount':58,'vat_amount':400,'total_amount':5000},\n",
    "         {'product_id':2, 'product_description':'Some product', 'product_price':5058,'discount_rate':1,'quantity':2,'full_price_amount':5058,'discounted_amount':58,'vat_amount':400,'total_amount':5000},\n",
    "            {'product_id':3, 'product_description':'Some product', 'product_price':5058,'discount_rate':1,'quantity':2,'full_price_amount':5058,'discounted_amount':58,'vat_amount':400,'total_amount':5000},\n",
    " \n",
    "])\n",
    "\n",
    "meta.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 'Ravi', 'Kapoor', datetime.datetime(2019, 4, 13, 0, 0), 1, 1, 'Some product', 5058, 1, 2, 5058, 58, 400, 5000)\n(2, 'Rajiv', 'Khanna', datetime.datetime(2016, 9, 1, 0, 0), 2, 2, 'Some product', 5058, 1, 2, 5058, 58, 400, 5000)\n(3, 'Komal', 'Bhandari', datetime.datetime(2017, 2, 3, 0, 0), 3, 2, 'Some product', 5058, 1, 2, 5058, 58, 400, 5000)\n(4, 'Abdul', 'Sattar', datetime.datetime(2018, 3, 5, 0, 0), 4, 3, 'Some product', 5058, 1, 2, 5058, 58, 400, 5000)\n"
    }
   ],
   "source": [
    "from sqlalchemy.sql import select\n",
    "s = select([orders, orderlines]).where(orders.c.id == orderlines.c.id)\n",
    "result = conn.execute(s)\n",
    "\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-109-28d3348d5dc2>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-109-28d3348d5dc2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    The total number of items sold on that day.\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The total number of items sold on that day.\n",
    "The total number of customers that made an order that day.\n",
    "The total amount of discount given that day.\n",
    "The average discount rate applied to the items sold that day.\n",
    "The average order total for that day\n",
    "The total amount of commissions generated that day.\n",
    "The average amount of commissions per order for that day.\n",
    "The total amount of commissions earned per promotion that day.\n",
    "•\n",
    "•\n",
    "•\n",
    "•\n",
    "•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<sqlalchemy.engine.result.ResultProxy object at 0x079D1058>\n(20000,)\n"
    }
   ],
   "source": [
    "# The total number of items sold on that day.\n",
    "from sqlalchemy.sql import select\n",
    "import sqlalchemy as db\n",
    "s=select([db.func.sum(orderlines.columns.total_amount)])\n",
    "result = conn.execute(s)\n",
    "print(result)\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<sqlalchemy.engine.result.ResultProxy object at 0x07821D48>\n(1, datetime.datetime(2020, 5, 4, 0, 0))\n(1, datetime.datetime(2019, 4, 13, 0, 0))\n(1, datetime.datetime(2018, 7, 5, 0, 0))\n(1, datetime.datetime(2018, 3, 5, 0, 0))\n(1, datetime.datetime(2017, 2, 3, 0, 0))\n(1, datetime.datetime(2016, 9, 1, 0, 0))\n"
    }
   ],
   "source": [
    "# The total number of customers that made an order that day.\n",
    "\n",
    "from sqlalchemy.sql import select\n",
    "import sqlalchemy as db\n",
    "s=select([db.func.count(orders.columns.customer_id),orders.columns.created_at]).group_by(orders.columns.created_at).order_by(db.desc(orders.columns.created_at))\n",
    "result = conn.execute(s)\n",
    "print(result)\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<sqlalchemy.engine.result.ResultProxy object at 0x0783CAD8>\n(20000, datetime.datetime(2018, 7, 5, 0, 0))\n(20000, datetime.datetime(2016, 9, 1, 0, 0))\n(20000, datetime.datetime(2019, 4, 13, 0, 0))\n(20000, datetime.datetime(2017, 2, 3, 0, 0))\n(20000, datetime.datetime(2018, 3, 5, 0, 0))\n(20000, datetime.datetime(2020, 5, 4, 0, 0))\n"
    }
   ],
   "source": [
    "# The total amount of discount given that day\n",
    "from sqlalchemy.sql import select\n",
    "import sqlalchemy as db\n",
    "s=select([db.func.sum(orderlines.columns.total_amount),orders.columns.created_at]).group_by(orders.columns.created_at)\n",
    "result = conn.execute(s)\n",
    "print(result)\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<sqlalchemy.engine.result.ResultProxy object at 0x07EA2658>\n(Decimal('58.0000000000000000'), datetime.datetime(2018, 7, 5, 0, 0))\n(Decimal('58.0000000000000000'), datetime.datetime(2016, 9, 1, 0, 0))\n(Decimal('58.0000000000000000'), datetime.datetime(2019, 4, 13, 0, 0))\n(Decimal('58.0000000000000000'), datetime.datetime(2017, 2, 3, 0, 0))\n(Decimal('58.0000000000000000'), datetime.datetime(2018, 3, 5, 0, 0))\n(Decimal('58.0000000000000000'), datetime.datetime(2020, 5, 4, 0, 0))\n"
    }
   ],
   "source": [
    "# The average discount rate applied to the items sold that day.\n",
    "\n",
    "\n",
    "from sqlalchemy.sql import select\n",
    "import sqlalchemy as db\n",
    "s=select([db.func.avg(orderlines.columns.discounted_amount),orders.columns.created_at]).group_by(orders.columns.created_at)\n",
    "result = conn.execute(s)\n",
    "print(result)\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<sqlalchemy.engine.result.ResultProxy object at 0x07DEC1F0>\n(Decimal('5000.0000000000000000'), datetime.datetime(2018, 7, 5, 0, 0))\n(Decimal('5000.0000000000000000'), datetime.datetime(2016, 9, 1, 0, 0))\n(Decimal('5000.0000000000000000'), datetime.datetime(2019, 4, 13, 0, 0))\n(Decimal('5000.0000000000000000'), datetime.datetime(2017, 2, 3, 0, 0))\n(Decimal('5000.0000000000000000'), datetime.datetime(2018, 3, 5, 0, 0))\n(Decimal('5000.0000000000000000'), datetime.datetime(2020, 5, 4, 0, 0))\n"
    }
   ],
   "source": [
    "# The average order total for that day\n",
    "\n",
    "from sqlalchemy.sql import select\n",
    "import sqlalchemy as db\n",
    "s=select([db.func.avg(orderlines.columns.total_amount),orders.columns.created_at]).group_by(orders.columns.created_at)\n",
    "result = conn.execute(s)\n",
    "print(result)\n",
    "for row in result:\n",
    "   print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'DATABASE_URI=postgresql://postgres:developpassword@image-storage-db/postgres\\n             dialect+driver://username:password@host:port/database\\n             postgresql://scott:tiger@localhost/mydatabase'"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    " '''DATABASE_URI=postgresql://postgres:developpassword@image-storage-db/postgres\n",
    "              dialect+driver://username:password@host:port/database\n",
    "              postgresql://scott:tiger@localhost/mydatabase'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"DATABASE_URI=postgresql://postgres:postgres@places-db/places\\napp.config['SQLALCHEMY_DATABASE_URI'] =postgresql://postgres:postgres@places-db/places\\napp.config['SQLALCHEMY_DATABASE_URI'] =postgresql://postgres:postgres@192.168.99.100:5436/places\""
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    " '''DATABASE_URI=postgresql://postgres:postgres@places-db/places\n",
    " app.config['SQLALCHEMY_DATABASE_URI'] =postgresql://postgres:postgres@places-db/places\n",
    " app.config['SQLALCHEMY_DATABASE_URI'] =postgresql://postgres:postgres@192.168.99.100:5436/places'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:////tmp/test.db'\\nFor SQLlite, you just need a file path (as above) For MySQL, I have our app set up like so:\\n\\napp.config['SQLALCHEMY_DATABASE_URI'] = 'mysql+pymysql://username:password@server.site.com/database'\\nYou can read way more than you ever wanted to know about this in the SQLAlchemy docs:\\n\\nhttp://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls\""
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "'''app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:////tmp/test.db'\n",
    "For SQLlite, you just need a file path (as above) For MySQL, I have our app set up like so:\n",
    "\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql+pymysql://username:password@server.site.com/database'\n",
    "You can read way more than you ever wanted to know about this in the SQLAlchemy docs:\n",
    "\n",
    "http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "iyhuj\n"
    }
   ],
   "source": [
    "print(\"iyhuj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\ndocker exec -it reports-db psql -U postgres\\n\\nDROP SCHEMA public CASCADE;\\nCREATE SCHEMA public;\\n\\n\\ndrop table if exists orders2;\\nEntering the postgres container\\nOnce the application is running, open a new Docker terminal or the equivalent, and run the following command\\n\\ndocker exec -it postgres psql -U postgres\\nThis command runs the psql command (which is the command line for PostgreSQL) under the user postgres.\\n\\nConnecting to a database\\nPostgreSQL can have multiple databases inside of it. In order to connect to one, you need to run the following command\\n\\n\\\\c <database_name>\\nViewing the tables\\nTo check all the tables that exist inside a database, run\\n\\n\\\\d\\nTo check the details of a particular table, run\\n\\n\\\\d+ <table_name>\\nExiting the container\\nTo exit the container, run the following command\\n\\n\\\\q\\n'"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "'''\n",
    "docker exec -it reports-db psql -U postgres\n",
    "\n",
    "DROP SCHEMA public CASCADE;\n",
    "CREATE SCHEMA public;\n",
    "\n",
    "\n",
    "drop table if exists orders2;\n",
    "Entering the postgres container\n",
    "Once the application is running, open a new Docker terminal or the equivalent, and run the following command\n",
    "\n",
    "docker exec -it postgres psql -U postgres\n",
    "This command runs the psql command (which is the command line for PostgreSQL) under the user postgres.\n",
    "\n",
    "Connecting to a database\n",
    "PostgreSQL can have multiple databases inside of it. In order to connect to one, you need to run the following command\n",
    "\n",
    "\\c <database_name>\n",
    "Viewing the tables\n",
    "To check all the tables that exist inside a database, run\n",
    "\n",
    "\\d\n",
    "To check the details of a particular table, run\n",
    "\n",
    "\\d+ <table_name>\n",
    "Exiting the container\n",
    "To exit the container, run the following command\n",
    "\n",
    "\\q\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\ntabases installed locally.\\n\\ndocker exec -it postgres1 sh\\nInside that shell we can ask it to create a new database with the name mydb.\\n\\n# createdb -U postgres mydb\\nAnd then let's launch the psql utility which is a CLI tool for PostgreSQL, connected to our mydb database:\\n\\n# psql -U postgres mydb\\nExplore the database\\nNow inside psql, let's run some basic commands. \\\\l lists the databases. We'll also ask for the database version, and the current date:\\n\\nmydb=# \\\\l\\nmydb=# select version();\\nmydb=# select current_date;\\nNow let's do something a bit more interesting. We'll create a table:\\n\\nmydb=# CREATE TABLE people (id int, name varchar(80));\\nmydb=# INSERT INTO people (id,name) VALUES (1, 'Mark');\\nmydb=# SELECT * FROM people;\\n\\nNow we can quit from psql with \\\\q and exit from our shell\\n\\nmydb=# \\\\q \\n\\n--------------------------------------------\\n\\n a = db.session.query(User, UserGroups, Areas\\n ).filter(User.user_id==1\\n ).join(UserGroup,User.usergroup==UserGroup.group_id\\n ).join(Areas, User.area==Areas.area_id\\n ).first()\\n\""
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "'''\n",
    "tabases installed locally.\n",
    "\n",
    "docker exec -it postgres1 sh\n",
    "Inside that shell we can ask it to create a new database with the name mydb.\n",
    "\n",
    "# createdb -U postgres mydb\n",
    "And then let's launch the psql utility which is a CLI tool for PostgreSQL, connected to our mydb database:\n",
    "\n",
    "# psql -U postgres mydb\n",
    "Explore the database\n",
    "Now inside psql, let's run some basic commands. \\l lists the databases. We'll also ask for the database version, and the current date:\n",
    "\n",
    "mydb=# \\l\n",
    "mydb=# select version();\n",
    "mydb=# select current_date;\n",
    "Now let's do something a bit more interesting. We'll create a table:\n",
    "\n",
    "mydb=# CREATE TABLE people (id int, name varchar(80));\n",
    "mydb=# INSERT INTO people (id,name) VALUES (1, 'Mark');\n",
    "mydb=# SELECT * FROM people;\n",
    "\n",
    "Now we can quit from psql with \\q and exit from our shell\n",
    "\n",
    "mydb=# \\q \n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    " a = db.session.query(User, UserGroups, Areas\n",
    " ).filter(User.user_id==1\n",
    " ).join(UserGroup,User.usergroup==UserGroup.group_id\n",
    " ).join(Areas, User.area==Areas.area_id\n",
    " ).first()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "jgmj\n"
    }
   ],
   "source": [
    "print(\"jgmj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38132bit5b811d093ce74921a906d512c2355267",
   "display_name": "Python 3.8.1 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}